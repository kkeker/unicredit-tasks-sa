# Общие правила для проектируемых систем

## Пояснение по нотации

Диаграммы используют нотацию ArchiMate раздела Application.

- Системы: Платформа данных, Каталог бизнес-событий и Система проверки паспортов по черным спискам, Система Уведомлений - являются Служебными Сервисами, поскольку не выполняют непосредственных бизнес-операций и не предоставляют продукты. У них может быть или не быть пользовательского интерфейса для управления, но их функции в основном утилитарны.
- Системы: Карточка ФЛ, Карточка ЮЛ, Связи ЮЛ и Системы-потребители, Биллинг, АБС, ДБО и т.д. - считаются Системами Устойчивых Бизнес Операций, так как они реализуют бизнес-сервисы и участвуют в бизнес-процессах.
- Системы: "ИС МВД РФ черные списки паспортов", "Оператор SMS уведомлений", "Оператор Push уведомлений" и не указанные на схеме системы-источники данных для Связей ЮЛ, такие как платформы открытых данных РФ, рассматриваются как сторонние системы.

Концептуальная архитектура не включает в себя интерфейсы и протоколы взаимодействия и не раскрывает деталей реализации конкретной ИС, а только обобщенно отображает процесс взаимодействия. В данном контексте связи интерпретируются как "Использует", независимо от потока данных.

## Правила создания систем

Подобные системы реализуются единообразно, и их основные правила следующие:
- Каждая система имеет свою Физическую модель данных (ФМД), обычно отображаемую как ER-диаграмма нотации "Воронья лапка" для реляционных БД или диаграмма Классов UML для NoSQL баз данных. Физическая модель представляет собой контракт и описание бизнес-сущностей в виде Логической модели данных (ЛМД). Совокупность всех моделей ЛМД формирует Единую модель данных (ЕМД) компании.
- Все интерфейсы системы строятся как интерфейсы операций над сущностями Логической модели данных (объектами объектной модели). Поэтому системы могут иметь несколько интерфейсов для разных сценариев использования. Обычно это REST API, Kafka для входящих и исходящих стриминг-процессов, ArtemisMQ для очередей сообщений и отправки бизнес-событий в Каталог бизнес-событий, а также Kafka-стрим для Логической модели данных в Платформу данных для создания витрин, отчетов и агрегаций (может использоваться как контрольный канал). Интерфейсы являются опциональными и зависят от сценария использования, но не считаются избыточными, так как реализуются в единообразной манере. Если в компании существует зрелая практика Data Governance и понимание разницы между физической моделью хранения данных и логической моделью данных, а также согласованная единая модель данных для всей компании, то все интерфейсы могут быть построены как операции над сущностями логической модели данных. Если компания может позволить себе перейти на транспорт gRPC, то задача становится еще более простой, так как gRPC может использоваться для синхронного запрос-ответ и других сценариев использования, включая асинхронное взаимодействие и стриминг данных в ту же платформу данных. Если в компании используется подход DDD (Domain-Driven Design), то доменные события могут легко превращаться в бизнес-события для Каталога бизнес-событий. Но даже без этого подхода формирование этих событий не должно вызывать проблем, если есть понимание логической модели данных ИС и нотификации из ее объектов.
- Платформа данных представляет из себя набор систем класса Data Lake и DWH, а также вспомогательные системы, такие как Kafka для приема стриминга данных или ETL для приема данных от других ИС по разным протоколам. Она может содержать ML-инструменты для создания дата-продуктов, кеш-системы для ускорения чтения/записи и различные хранилища, включая объектные, файловые, реляционные, ключ-значение, графовые, документные и другие. Дата-продукт в такой системе обычно представляет собой автоматизированную микро-инсталляцию внутри Платформы данных, часть которой адаптирована под ваши функциональные и нефункциональные требования. Часто это хранилище настраивается в соответствии с объемами и требованиями хранения данных, системой агрегации данных на основе Единой модели данных, витринами данных и системами кеширования, специально адаптированными под вашу ИС, чтобы не замедлять работу слоя сбора и хранения данных внутри Платформы данных.
- Доступ к данным осуществляется через витрины Платформы данных, в которые такие системы направляют поток изменений, аналогичный CDC (Change Data Capture), в соответствии с их объектной логической моделью данных, соответствующей Единой модели данных компании.
- Имеется асинхронный интерфейс Apache Kafka в случае наличия большого объема данных, которые можно получить как поток по запросу или по инициативе самой системы (обновление данных в самой ИС).
- Имеется интеграция с Каталогом бизнес-событий, реализованным на базе Apache ActiveMQ Artemis (стандартом в банковской индустрии) с использованием протокола artemismq (не amqp), который регистрирует контракт, описание и триггер в реестре бизнес-событий Каталога бизнес-событий.
- Есть собственная база данных для хранения данных и возможно наличие кеша.
- Различные интерфейсы этой системы реализуют единую службу ИС.
- Система может состоять из подсистем и элементов, где единицы развертывания (deployment units) не имеют значения (монолит, SOA, MSA, облачная функция).
- Интерфейсы такой системы могут быть реализованы через сторонние интеграционные системы, такие как ESB, iPaaS, ServiceMesh, DataLake, DWH, но нотационно они относятся к ИС, которая предоставила эти интерфейсы.
- Все интерфейсы имеют строгие контракты, представленные в виде зарегистрированной модели изменений в Платформе данных, зарегистрированного формата событий в Каталоге бизнес-событий, зарегистрированного контракта REST API и строгого формата дизайна и набора компонентов для использования в каналах.
- Поток сообщений в Kafka между разными ИС и поток сообщений данных в Платформу данных представляют собой один и тот же логический поток данных модели данных ИС. Сообщения в Каталоге бизнес-событий представляют собой статусы той же самой логической модели данных, которая отправляется через Kafka. REST-интерфейсы должны предоставлять операции над той же самой логической моделью данных, которая предоставляется через другие интерфейсы.
- Pub/Sub паттерн реализуется как на ActiveMQ Artemis, поддерживающей функционал отправки одного и того же сообщения разным получателям и статус обработки сообщения, так и на кастомном решении поверх Tarantool (пример Mail.ru Cloud) (моя собственная реализация такой системы находится в закрытом репозитории).
- Каталог бизнес-событий является более зрелым решением, чем просто MQ, Straming или Pub/Sub-системы. Часто он отличается набором различных протоколов интеграции, от HTTP до каких-то проприетарных. Основным плюсом является его контрактная модель работы и система подписок, напоминающая WebSub. В таких системах вы не просто отправляете что-то в систему, показав максимум свой JSON для интеграции, а регистрируете свои сообщения в удобном каталоге с дополнительной метаинформацией о системе или даже разрабатывающей команде. Это что-то вроде DevPortal, в котором можно заказать в том числе составные сообщения из ряда ИС с учетом условий. Это переход от EDA-архитектуры к EBA. Примерами могут служить eventcatalog.dev и Amazon EventBridge.
- ArtemisMQ - После постепенного отхода IBM MQ из банковского сектора новым стандартом в этой области становится Apache ActiveMQ 5, который также известен как Apache ActiveMQ Artemis, или ArtemisMQ. Эта система не является просто продолжением старого Apache ActiveMQ 4 (который также называется Apache ActiveMQ Classic), который перестал справляться с потребностями современного мира. Эту систему полностью переработали, и она стала новым банковским стандартом даже для индустрии NeoBanking, где примером может служить Corda на основе Blockchain для главной книги многих банков. И не стоит забывать, что системы класса MQ, Straming или Pub/Sub-системы плохо сочетаются с функциями своих соседей.
- Не отправляйте сами данные в уведомлениях. Для предотвращения раскрытия информации и возможности создания подписок только на легкие уведомления, агрегации и управления ими в системах, которым не нужны сами данные (например, для дальнейших push-уведомлений).
- Apache Kafka используется для передачи данных. Эта система относится к классу Streaming и отличается от MQ или Pub/Sub систем в сценариях использования, что делает ее отличным выбором для передачи больших объемов данных между системами в стиле потока изменений, подобно CDC. В отличие от аналогичных продуктов, таких как RedPanda или Pulsar, Kafka является более популярным решением и обладает встроенным Java Application Server, который позволяет встраивать логику внутри стриминг-системы, такую как обогащение данных, агрегация, работа с kSQL или создание Kafka Connector. Более того, эта система в теории CAP скорее выступает как консистентная система с высокой степенью гарантии консистентности данных.
- Все системы выгружают свои данные в главное хранилище в формате Логической модели данных для создания Единой модели данных, а не используют только собственные БД. Собственные хранилища также используются, потому что схемы данных в собственных хранилищах могут меняться намного чаще, чем логические модели в Платформе данных. Также локальные хранилища ИС могут использовать другие технологии, например, из экспериментального стека компании. В них также могут храниться уникальные для ИС сущности, не входящие в модель данных этой ИС, такие как кеши других ИС, архивы, логи (плохой пример, но бывает), и так далее. Платформа данных обычно не является бесконечным хранилищем всех данных ИС, а только сущностей, соответствующих модели данных и практикам управления данными компании. С точки зрения финансовых затрат этот подход примерно сопоставим с расходами на хранение такого же объема данных непосредственно в самих ИС, только лишен проблем, связанных с агрегацией нескольких моделей данных разных соседних ИС. Таким образом, в таких системах обычно контролируется качество данных, и может происходить агрегация данных с разных ИС в рамках единой модели данных компании. С точки зрения финансовых затрат этот подход примерно сопоставим с расходами на хранение такого же объема данных прямо в ИС, только лишен проблем, когда ИС нужно агрегировать несколько моделей данных разных соседних ИС, и в этом случае придется создавать копии данных и агрегировать их.
- ETL и ELT. Выбор между хорошим ETL уровня Enterprise, таким как Informatica PowerCenter, бесплатным Apache NiFi и чем-то самописанным, если таких задач мало. Если нет возможности использовать ETL, то самописанный вариант можно рассматривать на основе Apache Spark, потому что это отличный оркестратор распределенных заданий трансформации данных для Java, Scala, Python и R, который может следить за каждым потоком заданий отдельно, нарезать потоки на задачи, оптимизировать производительность, разделять потоки чтения и записи, а в промежутке использовать RDD-файлы как журнал смещения для повторов после прерывания заданий (для этого потребуется S3-совместимое хранилище). Этому решению не хватает только планировщика задач, вроде Spring Task Scheduler, что позволит собрать всю конструкцию внутри приложения Spring Boot, если использовать Spark как библиотеку.
- Выбор БД. В данном решении используются два типа БД - реляционный и графовый. В качестве реляционного решения предлагается использовать Open Source или сертифицированный ФСБ вариант PostgreSQL. В качестве графовой БД рекомендуется использовать Open Source решение - ArangoDB, которая имеет преимущество перед Dgraph, Neo4j и AWS Neptune, поскольку она не является коммерческим продуктом или SaaS-решением. Отдельным пунктом является слой хранения данных в DWH в составе платформы данных, на сегодняшний день лидером решений в этом направлении в РФ является ArenadataDB, включая государственный сектор, банки и тяжелую промышленность.
- Transaction Outbox - обязательный паттерн при работе с Платформой данных или в других случаях консистентной доставки сообщений через очередь или стриминг. Обычно для этого используется готовый продукт Debezium, реализующий паттерн CDC. Близнец Transaction Outbox может реализовываться при помощи ETL на стороне получателя. Для большей надежности могут использоваться вспомогательные каналы данных между ИС на асинхронном транспорте - поток статусов получения (RPC паттерн), обработки или записи (2PC паттерн) и очередь неразобранных сообщений (DLQ паттерн). Все вместе они реализуют [Enterprise Integration Patterns](https://www.enterpriseintegrationpatterns.com/) (EIP Грегора Хопа).
- Кеширование. Хорошим Enterprise-решением для кеширования являются [встроенные механизмы Tarantool](https://www.tarantool.io/en/patterns/), напоминающие работу CDC, которые копируют все изменения и как бы становятся частью кластера БД (хотя на самом деле нет). Промышленное использование в крупных компаниях в РФ - один из крупных банков из ТОП3 (не могу разглашать) и [Аэрофлот](https://habr.com/ru/companies/vk/articles/497404/). Альтернативами могут быть эфемерные бакеты CouchBase Enterprise или Hazelcast IMDG, которые также проверены многими компаниями, включая крупнейший ритейл в РФ.


### Интеграционные сценарии
1. REST API - синхронные запросы от пользовательского интерфейса (UI) или другой информационной системы (ИС), когда требуется синхронный процесс, количество данных ограничено и запрос/ответ не создают значительной нагрузки, при этом укладываются в ожидаемые временные рамки.
2. Kafka - асинхронный стриминг объектной модели данных, может быть потребляем напрямую другой ИС или через платформу данных, где данные будут преобразованы в модель хранения. Также Kafka может сопоставляться с моделями других ИС, что позволяет создавать дата-продукты. Kafka может действовать как инициатор получения данных (Event-Driven Architecture, EDA), или использоваться для дублирования событий из каталога бизнес-событий с целью проверки и повторной передачи данных. Кроме того, интерфейс Kafka может быть задействован для выполнения пакетных операций обработки данных, которые не могут быть реализованы через REST.
3. DB Connect - синхронное получение данных исключительно из платформы данных, исключая запросы между ИС. Это может представлять собой дата-продукт в виде отдельной кешированной системы-витрины поверх собственной системы хранения данных, оптимизированной для OLAP-нагрузки. Также это может быть представление (view) внутри базы данных ИС, доступ к которому разрешен только ETL-платформам данных, если сама ИС не способна предоставить данный поток.
4. ArtemisMQ - асинхронный событийный интерфейс через iPaaS, такой как Каталог бизнес-событий, где события могут быть агрегированы из разных ИС (например, события, связанные с процессом выдачи кредитов в банковском конвейере). ArtemisMQ может выступать в качестве инициатора получения данных из платформы данных или через REST API.

Таким образом, данные можно получать напрямую от ИС через REST или Kafka, а также через DB Connect в платформе данных. Возможны комбинированные варианты. Инициаторами могут служить расписания, пользовательские действия в других ИС, процессы в них, события в каталоге бизнес-событий или сам поток Kafka. Платформу данных можно использовать напрямую с выделением дата-продукта (как отдельная подсистема с определенными характеристиками хранения, кэширования и представлениями данных, соответствующими функциональным и нефункциональным требованиям), или можно читать данные из нее во внутреннюю промежуточную базу данных для создания обновляемого кеша для быстрого доступа.